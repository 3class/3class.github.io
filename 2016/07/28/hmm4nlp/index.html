






<!doctype html>
<html lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="author" content="Haotian Wu">
  
  
  
  
    <meta name="description" content="看到网上有很多分词、词性标注的工具，但大多是已经训练过的模型，有些可以添加一些自定义的词典来定制模型。趁同学给了我一些nlp的中文语料数据，我就尝试自己实现一个简单的HMM（隐马尔科夫模型）来进行中文的词性标注（Part-of-Speech tagging或POS tagging，以下简称tag）、分词（Segmentation，以下简称seg）和命名实体识别（Named Entity Re...">
  
  <title>NLP中使用HMM进行tag、seg和ner [ tripleday ]</title>
  
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
  <link rel="stylesheet" href="/css/random.css">
<link rel="stylesheet" href="/css/vegas.min.css">
<link rel="stylesheet" href="/css/highlight-railscasts.css">
<link rel="stylesheet" href="/css/jquery.fancybox.css">
<link rel="stylesheet" href="/css/iconfont/iconfont.css">
<link rel="stylesheet" href="/css/jquery.fancybox-thumbs.css">
<link rel="stylesheet" href="/css/plyr.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
</head>

<body>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="side-navigate hide-area">
  
    <div class="item prev">
      <a href="/2016/10/06/graphite/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        CentOS下使用Graphite监测Scrapy
      </div>
    </div>
  
  
    <div class="item next">
      <a href="/2016/07/20/img2txt/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        使用python将图片转化为字符画
      </div>
    </div>
  
</div>
<div id="outer-container" class="hide-area">
<div id="container">
  <div id="menu-outer" class="slide-down">
    <div id="menu-inner">
      <div id="brand">
        
        <a onClick="openUserCard()">
          <img id="avatar" src="https://avatars3.githubusercontent.com/u/16516510?v=3&s=460"/>
          <div id="homelink">tripleday</div>
        </a>
      </div>
      <div id="menu-list">
        <ul>
        
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/archives">Archives</a></li>
        
          <li><a href="/tags">Tags</a></li>
        
          <li><a href="/categories">Categories</a></li>
        
          <li><a href="/about">About</a></li>
        
        </ul>
      </div>
      <div id="show-menu">
        <button>Menu</button>
      </div>
    </div>
  </div>

  <div id="content-outer">
    <div id="content-inner">
      
      
  <article id="post">
    <h1>NLP中使用HMM进行tag、seg和ner</h1>
    <p class="page-title-sub">
      <span id = "post-title-date">Created at 2016-07-28</span>
      
        <span id = "post-title-updated">Updated at 2016-09-02</span>
      
      
      <span id = "post-title-categories">Category
      
      
        
        
        <a href="/categories/NLP/">NLP</a>
      
      </span>
      
      
      <span id = "post-title-tags">
      Tag
      
      
        
        
        <a href="/tags/python/">python</a>
      
        
          /
        
        
        <a href="/tags/HMM/">HMM</a>
      
      </span>
      
    </p>
    
      <div class="center-title">

  <a class="fancybox-thumb" rel="fancybox-thumb" href="/uploads/img/20160728/cover.png">
    <img src="/uploads/img/20160728/cover.png" />
  </a>

</div>

    
    <p>看到网上有很多分词、词性标注的工具，但大多是已经训练过的模型，有些可以添加一些自定义的词典来定制模型。趁同学给了我一些nlp的中文语料数据，我就尝试自己实现一个简单的HMM（隐马尔科夫模型）来进行中文的词性标注（Part-of-Speech tagging或POS tagging，以下简称<strong>tag</strong>）、分词（Segmentation，以下简称<strong>seg</strong>）和命名实体识别（Named Entity Recognition，以下简称<strong>ner</strong>）。</p>
<p>具体关于HMM的内容，这篇博文里面不做赘述，读者可以自行学习了解，也可以参考本人之前的一篇博文<a href="http://tripleday.github.io/2016/07/14/hmm-memm-crf/">HMM、MEMM和CRF的学习总结</a>和里面提供的一些链接。</p>
<h1 id="代码相关"><a href="#代码相关" class="headerlink" title="代码相关"></a>代码相关</h1><p>整个HMM的代码和相关测试数据已上传至Github上，附上<a href="https://github.com/tripleday/simple_HMM" target="_blank" rel="external">链接</a>。整个代码的实现有部分学习参考博客<a href="http://blog.csdn.net/soundfuture/article/details/4135216" target="_blank" rel="external">python词法分析(分词+词性标注）</a>，感谢博主的分享。</p>
<ul>
<li><p>文件图如下：<br><img src="/uploads/img/20160728/file.png" alt=""><br>这四个文件夹中都是用的是同一个HMM模型，只是测试数据和目标任务不同而已。其中tag相关的有两个：conll_tag和pku_tag，conll_tag使用的CoNLL-2000的英文数据，具体数据下载见<a href="http://www.cnts.ua.ac.be/conll2000/chunking/" target="_blank" rel="external">Chunking</a>，pku_tag使用的一个北大同学给的课程作业的中文语料数据。pku_seg和pku_ner同理分别是在相应的数据上进行的分词和命名实体识别。</p>
</li>
<li><p>其实，seg和ner的实现依赖于tag的词性标注，只是seg、ner要学习的的标签不同。整个HMM的实现也中规中矩，从语料数据中学习转移概率、发射概率等等，然后利用viterbi算法求解最大路径。其中在计算路径概率的时候，为了防止概率相乘过小约等于零的情况，程序取概率对数再取反，将概率相乘转化为对数相加。</p>
</li>
</ul>
<h1 id="tag"><a href="#tag" class="headerlink" title="tag"></a>tag</h1><ul>
<li><p>数据说明<br>tag这里指语句的词性标注，当然不同的语料采用的词性体系不太相同。</p>
<ul>
<li>conll2000为英文语料，给出的数据一共有三列，每一列代表的含义在上面给出的链接里有提及。第一列是英文单词本身，<strong>第二列</strong>是由Brill tagger标注的词性，<strong>第三列</strong>是华尔街日报语料库产生的标注，其实第三列的标注和分词的标注方法类似。</li>
<li>pku的数据是中文语料，且已经进行过分词操作，它的词性标注与<a href="http://wenku.baidu.com/view/3c5488b75ef7ba0d4b733b1a" target="_blank" rel="external">近代汉语词类标注简表</a>相似但不完全相同。</li>
</ul>
</li>
<li><p>测试结果<br>关于准确率，程序将数据七三分做交叉验证来计算。conll2000对第二列的<strong>Brill tagger</strong>的准确率约为94.09%，对第三列的<strong>WSJ corpus</strong>的准确率约为87.93%。pku的准确率约为93.0%。</p>
</li>
<li><p>结果分析</p>
<ul>
<li>本文实现的HMM对实际详细的词性标注如conll的Brill tagger和pku的标注有较好的效果，而conll的WSJ corpus的标注偏向语句的分词，效果会差一些。</li>
<li>我实现的HMM在训练完进行标注的时候，没有去检测一些数字，日期等等的存在，而是单纯地看它在不在训练集里，比如之前训练时统计到过6.11是数字，但没见过6.12，那之后就标注不出来了。这是很大一块需要改进的地方。</li>
</ul>
</li>
</ul>
<h1 id="seg"><a href="#seg" class="headerlink" title="seg"></a>seg</h1><ul>
<li><p>处理思路<br>seg的处理思路就是将训练数据转化为上一项tag（POS Tagging）所需的训练数据格式，程序里我采用的是4-tag（B（Begin，词首）, E（End，词尾）, M（Middle，词中）, S（Single,单字词））标记集。这里转化来转化去的脚本需要自己写。关于这种标记方法和转化过程的详细介绍可以参考这篇<a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%953" target="_blank" rel="external">中文分词入门之字标注法3</a>。</p>
</li>
<li><p>测试结果<br>对pku的数据测试得到的准确率为92.13%，召回率为91.88%，F1值为92.01%。</p>
</li>
</ul>
<h1 id="ner"><a href="#ner" class="headerlink" title="ner"></a>ner</h1><ul>
<li><p>数据说明<br>ner的训练数据里，非命名实体的都标注为N，“北京市”中“北”标为“B-LOC”，代表为地名的开始，“京”和“市”跟在后面则标为“I-LOC”。在最后计算准确率和召回率的时候，标为“N”的字都不需要考虑，仅看那些命名实体是否被标注出来。</p>
</li>
<li><p>测试结果<br>对pku的数据测试得到的准确率为67.6%，召回率为63.9%，F1值为65.7%。</p>
</li>
<li><p>结果分析<br>从结果可以看出，在不使用规则或字典等其他方法干预的情况下，单纯使用HMM对命名实体识别效果较差。</p>
</li>
</ul>

  </article>
  <div class="random-toc-area">
  <button class="btn-hide-toc btn-hide-toc-show" style="display: none" onclick="TOCToggle()">Show TOC</button>
  <button class="btn-hide-toc btn-hide-toc-hide" onclick="TOCToggle()">Hide TOC</button>
  <div class="random-toc">
    <h2>Table of Content</h2>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#代码相关"><span class="toc-text">代码相关</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tag"><span class="toc-text">tag</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#seg"><span class="toc-text">seg</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ner"><span class="toc-text">ner</span></a></li></ol>
  </div>
</div>

  
<nav id="pagination">
  
    <a href="/2016/10/06/graphite/" class="prev">&larr; Prev post CentOS下使用Graphite监测Scrapy</a>
  

  

  
    <a href="/2016/07/20/img2txt/" class="next">Next post 使用python将图片转化为字符画 &rarr;</a>
  
</nav>

  <!-- JiaThis Button BEGIN -->

<!-- JiaThis Button END -->


      
      <div class="ds-thread" data-thread-key="2016/07/28/hmm4nlp/" data-title="NLP中使用HMM进行tag、seg和ner" data-url="http://tripleday.github.io/2016/07/28/hmm4nlp/"></div>
      
      
      
    </div>
  </div>

  <div id="bottom-outer">
    <div id="bottom-inner">
      Site by Haotian Wu using
      <a href="http://hexo.io">Hexo</a> & <a href="https://github.com/stiekel/hexo-theme-random">Random</a>
      <br>
      
    </div>
  </div>
</div>

</div>

  <script type="text/javascript">
var duoshuoQuery = {short_name:"tripleday"};
(function() {
  var ds = document.createElement('script');
  ds.type = 'text/javascript';ds.async = true;
  ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
  ds.charset = 'UTF-8';
  (document.getElementsByTagName('head')[0] 
   || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script>



<div id="user-card">
  <div class="center-field">
    <img class="avatar" src="https://avatars3.githubusercontent.com/u/16516510?v=3&s=460">
    <p id="description">Life is short, you need Python.</p>
    <ul class="social-icon">
  
  
    <li>
      <a href="https://github.com/tripleday">
        
          <i class="icon iconfont github">&#xe606;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://www.zhihu.com/people/wu-hao-tian-73">
        
          <i class="icon iconfont zhihu">&#xe60b;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://www.facebook.com/haotianwuseu">
        
          <i class="icon iconfont facebook">&#xe604;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://twitter.com/kjhn15">
        
          <i class="icon iconfont twitter">&#xe600;</i>
        
      </a>
    </li>
  
    <li>
      <a href="http://weibo.com/3241222987">
        
          <i class="icon iconfont weibo">&#xe602;</i>
        
      </a>
    </li>
  
</ul>
  </div>
</div>


<div id="btn-view">Hide</div>

<script>
// is trigger analytics / tongji script
var isIgnoreHost = false;

if(window && window.location && window.location.host) {
  isIgnoreHost = ["localhost","127.0.0.1"].some(function(address){
    return 0 === window.location.host.indexOf(address);
  });
}

var isTriggerAnalytics = !( true && isIgnoreHost );

</script>

  <script>
if(isTriggerAnalytics) {
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?380bd64cb1b7792a4cb7151492fe6861";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
  })();
}
</script>



  <script>
if(isTriggerAnalytics) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-79173072-1', 'auto');
  ga('send', 'pageview');
}

</script>



  
  
    <script src="/js/jquery-2.2.3.min.js"></script>
  
    <script src="/js/vegas.min.js"></script>
  
    <script src="/js/random.js"></script>
  
    <script src="/js/highlight.pack.js"></script>
  
    <script src="/js/jquery.mousewheel.pack.js"></script>
  
    <script src="/js/jquery.fancybox.pack.js"></script>
  
    <script src="/js/jquery.fancybox-thumbs.js"></script>
  
    <script src="/js/plyr.js"></script>
  

<script>

  // fancybox
  var backgroundImages = [];
  
  $('#post').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox') || $(this).parent().hasClass('fancybox-thumb')) return;
      var alt = this.alt || this.title;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'post' + i);
    });
  });
  $(".fancybox").fancybox();

var vegasConfig = {"preload­Image":true,"transition":["slideLeft2","slideRight2","flash2"],"timer":true,"delay":5000,"shuffle":true,"count":28};
var unsplashConfig = {"gravity":"north"};

$(".fancybox-thumb").fancybox({
  prevEffect: 'none',
  nextEffect: 'none',
  helpers: {
    title: {
      type: 'outside'
    },
    thumbs: {
      width: 50,
      height: 50
    }
  }
});

// show video with plyr
$(".video-container iframe").each(function(i){
  var url = $(this).attr('src');
  var id = url.split('/').pop();
  var plyrContainer = document.createElement('div');
  plyrContainer.className = 'plyr';
  var plyrElement = document.createElement('div');
  plyrElement.dataset.videoId = id;
  switch(true) {
    case url.search('youtube.com') >= 0:
      plyrElement.dataset.type = 'youtube';
      break;
    case url.search('vimeo.com') >= 0:
      plyrElement.dataset.type = 'vimeo';
      break;
    default:
      return;
  };
  plyrContainer.appendChild(plyrElement);
  $(this).parent().html(plyrContainer);
});
plyr.setup('.plyr', {iconUrl: '/css/sprite.svg'});
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>

